{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20de0f22",
   "metadata": {},
   "source": [
    "# STA 243: Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f51217",
   "metadata": {},
   "source": [
    ">Hongye Li\n",
    "<br>\n",
    ">Ming Zhao\n",
    "<br>\n",
    ">05/06/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8228b099",
   "metadata": {},
   "source": [
    "## 1\n",
    "see pdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27110e40",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07154dd2",
   "metadata": {},
   "source": [
    "***\n",
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb21c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4124c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.data.csv\")\n",
    "test = pd.read_csv(\"test.data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd942ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15129 entries, 0 to 15128\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     15129 non-null  int64  \n",
      " 1   id             15129 non-null  int64  \n",
      " 2   date           15129 non-null  object \n",
      " 3   price          15129 non-null  int64  \n",
      " 4   bedrooms       15129 non-null  int64  \n",
      " 5   bathrooms      15129 non-null  float64\n",
      " 6   sqft_living    15129 non-null  int64  \n",
      " 7   sqft_lot       15129 non-null  int64  \n",
      " 8   floors         15129 non-null  float64\n",
      " 9   waterfront     15129 non-null  int64  \n",
      " 10  view           15129 non-null  int64  \n",
      " 11  condition      15129 non-null  int64  \n",
      " 12  grade          15129 non-null  int64  \n",
      " 13  sqft_above     15129 non-null  int64  \n",
      " 14  sqft_basement  15129 non-null  int64  \n",
      " 15  yr_built       15129 non-null  int64  \n",
      " 16  yr_renovated   15129 non-null  int64  \n",
      " 17  zipcode        15129 non-null  int64  \n",
      " 18  lat            15129 non-null  float64\n",
      " 19  long           15129 non-null  float64\n",
      " 20  sqft_living15  15129 non-null  int64  \n",
      " 21  sqft_lot15     15129 non-null  int64  \n",
      "dtypes: float64(4), int64(17), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5553377",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"price\"]\n",
    "y_test = test[\"price\"]\n",
    "\n",
    "X_train = train[[\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\"]]\n",
    "X_test = test[[\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "056d530f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "lr = LinearRegression() \n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960d0b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.08329891e+04],\n",
       "        [-5.92969566e+04],\n",
       "        [ 3.68165620e+03],\n",
       "        [ 3.16685731e+02],\n",
       "        [-4.26736772e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain coefficients w/o interaction\n",
    "lr_beta = np.matrix(np.append(lr.intercept_,lr.coef_)).T\n",
    "lr_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207a4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5101138530794578\n"
     ]
    }
   ],
   "source": [
    "# calculate R2 on training data\n",
    "y_pred_train = lr.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2f3de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5049944614037056\n"
     ]
    }
   ],
   "source": [
    "# calculate R2 on testing data\n",
    "y_pred_test = lr.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a765f",
   "metadata": {},
   "source": [
    "***\n",
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b0b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy = pd.read_csv(\"fancyhouse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae3402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fancy = fancy[[\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370e0568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15436769.53822435]\n"
     ]
    }
   ],
   "source": [
    "# predict price of Bill Gates' house\n",
    "y_pred_fancy = lr.predict(X_fancy)\n",
    "print(y_pred_fancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261f7a5",
   "metadata": {},
   "source": [
    "***\n",
    "#### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c38e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "\n",
    "X_train2[\"add_term\"] = X_train2[\"bedrooms\"] * X_train2[\"bathrooms\"]\n",
    "X_test2[\"add_term\"] = X_test2[\"bedrooms\"] * X_test2[\"bathrooms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e138931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "lr2 = LinearRegression() \n",
    "lr2.fit(X_train2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c650bf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.20752748e+05],\n",
       "        [-1.28706409e+05],\n",
       "        [-1.11008869e+05],\n",
       "        [ 3.08724841e+02],\n",
       "        [-4.24577540e-01],\n",
       "        [ 3.37536051e+04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain coefficients w interaction\n",
    "lr_beta2 = np.matrix(np.append(lr2.intercept_,lr2.coef_)).T\n",
    "lr_beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03395e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5173532927738305\n"
     ]
    }
   ],
   "source": [
    "# calculate R2 on training data\n",
    "y_pred_train2 = lr2.predict(X_train2)\n",
    "r2_train2 = r2_score(y_train, y_pred_train2)\n",
    "print(r2_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8ef31c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5105355458591379\n"
     ]
    }
   ],
   "source": [
    "# calculate R2 on testing data\n",
    "y_pred_test2 = lr2.predict(X_test2)\n",
    "r2_test2 = r2_score(y_test, y_pred_test2)\n",
    "print(r2_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66587f3a",
   "metadata": {},
   "source": [
    "***\n",
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c35be7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRGD (X, y, step_size = 0.001, n_iter = 1000, eps = 1e-6):\n",
    "    '''\n",
    "    Gradient Descent for linear regression\n",
    "    X is a n*p matrix\n",
    "    y is a n*1 vector\n",
    "    b is a p*1 vector\n",
    "    '''\n",
    "    \n",
    "    n, p = X.shape\n",
    "    \n",
    "    ones = np.ones((n, 1))\n",
    "    X = np.append(ones, X, axis = 1)\n",
    "    \n",
    "    b = np.zeros((p+1, 1))\n",
    "    \n",
    "    for t in range(n_iter):\n",
    "        \n",
    "        gradient = -2/n * X.T @ (y - X @ b) \n",
    "        b = b - step_size * gradient\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "        \n",
    "        if gradient_norm < eps:\n",
    "            break\n",
    "            \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80447940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st2unst(stb, y, X):\n",
    "    '''\n",
    "    Transformation on standardized coefficients\n",
    "    '''\n",
    "    \n",
    "    p = X.shape[1]\n",
    "    unstb = np.zeros((p+1, 1))\n",
    "    unstb_xbar = []\n",
    "    \n",
    "    for i in range(p):\n",
    "        unstb[i+1] = stb[i+1] * np.std(y) / np.std(X[:,i])\n",
    "        unstb_xbar.append(unstb[i+1] * np.mean(X[:,i])) \n",
    "        \n",
    "    unstb[0] = np.mean(y) - sum(unstb_xbar)\n",
    "    \n",
    "    return unstb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d881d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, betahat):\n",
    "    \"\"\"\n",
    "    linear regression prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    return betahat[0] + x @ betahat[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e24275d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to matrix\n",
    "X_train = np.matrix(X_train)\n",
    "y_train = np.matrix(y_train).T\n",
    "X_train2 = np.matrix(X_train2)\n",
    "\n",
    "X_test = np.matrix(X_test)\n",
    "y_test = np.matrix(y_test).T\n",
    "X_test2 = np.matrix(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0efb1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "X_train_scaled = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "y_train_scaled = (y_train - np.mean(y_train)) / np.std(y_train)\n",
    "X_train2_scaled = (X_train2 - np.mean(X_train2, axis=0)) / np.std(X_train2, axis=0)\n",
    "\n",
    "X_test_scaled = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
    "y_test_scaled = (y_test - np.mean(y_test)) / np.std(y_test)\n",
    "X_test2_scaled = (X_test2 - np.mean(X_test2, axis=0)) / np.std(X_test2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c41e3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for best step_size\n",
    "step_sizes = [0.1, 0.01, 0.001, 0.0001]\n",
    "beta = []\n",
    "beta2 = []\n",
    "for i in range(len(step_sizes)):   \n",
    "    beta.append(LRGD(X_train_scaled, y_train_scaled, step_size = step_sizes[i])) # models w/o interaction\n",
    "    beta2.append(LRGD(X_train2_scaled, y_train_scaled, step_size = step_sizes[i])) # models w interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf197f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform standardized coefficients to originals\n",
    "coef = []\n",
    "coef2 = []\n",
    "for i in range(len(step_sizes)):\n",
    "    coef.append(st2unst(beta[i], y_train, X_train))\n",
    "    coef2.append(st2unst(beta2[i], y_train, X_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2223fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best step_size by calculating average difference in coefficients between lr and gd methods\n",
    "diff = []\n",
    "diff2 = []\n",
    "for i in range(len(step_sizes)):\n",
    "    dis = np.mean(np.abs(lr_beta - coef[i]))\n",
    "    dis2 = np.mean(np.abs(lr_beta2 - coef2[i]))\n",
    "    diff.append(dis)\n",
    "    diff2.append(dis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b18fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22681480681664698, 654.0081452777072, 53004.42627743493, 65687.07594797036]\n",
      "[236.0990878360914, 47586.07636608571, 100243.84273616994, 62193.45760884956]\n"
     ]
    }
   ],
   "source": [
    "print(diff)\n",
    "print(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57873f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0.1 as final step_size\n",
    "gd_beta = coef[0]\n",
    "gd_beta2 = coef2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2b13c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.08329891e+04,  8.08325713e+04],\n",
       "        [-5.92969566e+04, -5.92968521e+04],\n",
       "        [ 3.68165620e+03,  3.68226741e+03],\n",
       "        [ 3.16685731e+02,  3.16685128e+02],\n",
       "        [-4.26736772e-01, -4.26734934e-01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare lr to gd results for models w/o interaction\n",
    "np.append(lr_beta, gd_beta, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "009d6e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.20752748e+05,  3.20009972e+05],\n",
       "        [-1.28706409e+05, -1.28494194e+05],\n",
       "        [-1.11008869e+05, -1.10646983e+05],\n",
       "        [ 3.08724841e+02,  3.08729394e+02],\n",
       "        [-4.24577540e-01, -4.24548946e-01],\n",
       "        [ 3.37536051e+04,  3.36538920e+04]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare lr to gd results for models w interaction\n",
    "np.append(lr_beta2, gd_beta2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60095a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5101138530785188\n",
      "0.5049944887919995\n"
     ]
    }
   ],
   "source": [
    "# perform part(a)\n",
    "\n",
    "# calculate R2 on training data\n",
    "gd_y_pred_train = predict(X_train, gd_beta)\n",
    "gd_r2_train = r2_score(y_train, gd_y_pred_train)\n",
    "print(gd_r2_train)\n",
    "\n",
    "# calculate R2 on testing data\n",
    "gd_y_pred_test = predict(X_test, gd_beta)\n",
    "gd_r2_test = r2_score(y_test, gd_y_pred_test)\n",
    "print(gd_r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59f34445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15436755.47672183]]\n"
     ]
    }
   ],
   "source": [
    "# perform part(b)\n",
    "\n",
    "# predict price of Bill Gates' house\n",
    "gd_y_pred_fancy = predict(np.matrix(X_fancy), gd_beta)\n",
    "print(gd_y_pred_fancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1c6d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5173532282363673\n",
      "0.5105385532390928\n"
     ]
    }
   ],
   "source": [
    "# perform part(c)\n",
    "\n",
    "# calculate R2 on training data\n",
    "gd_y_pred_train2 = predict(X_train2, gd_beta2)\n",
    "gd_r2_train2 = r2_score(y_train, gd_y_pred_train2)\n",
    "print(gd_r2_train2)\n",
    "\n",
    "# calculate R2 on testing data\n",
    "gd_y_pred_test2 = predict(X_test2, gd_beta2)\n",
    "gd_r2_test2 = r2_score(y_test, gd_y_pred_test2)\n",
    "print(gd_r2_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44533fa",
   "metadata": {},
   "source": [
    "***\n",
    "#### (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b230723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRSGD (X, y, step_size = 0.001, n_iter = 100000, eps = 1e-6):\n",
    "    '''\n",
    "    Stochastic Gradient Descent for OLS: \n",
    "        1. one observarion per iteration\n",
    "        2. sample without replacement\n",
    "    X is a n*p matrix\n",
    "    y is a n*1 vector\n",
    "    b is a p*1 vector\n",
    "    '''\n",
    "    n, p = X.shape\n",
    "    \n",
    "    ones = np.ones((n, 1))\n",
    "    X = np.append(ones, X, axis = 1)\n",
    "        \n",
    "    b = np.zeros((p+1, 1))\n",
    "    \n",
    "    data = np.append(y, X, axis = 1)   \n",
    "    \n",
    "    # calculate the times of running through the full data\n",
    "    if n_iter % n == 0: \n",
    "        I = n_iter // n\n",
    "    else:\n",
    "        I = n_iter // n + 1\n",
    "    \n",
    "    # obtain the sample index for each iteration\n",
    "    index = []\n",
    "    for i in range(I): \n",
    "        np.random.seed(i)\n",
    "        index = np.append(index, np.random.choice(n, n, replace=False))    \n",
    "    index = index[:n_iter]   \n",
    "    \n",
    "    t = 0\n",
    "    gradient_norm = 1\n",
    "    \n",
    "    while t < n_iter and gradient_norm >= eps:\n",
    "        \n",
    "        for ind in index: \n",
    "        \n",
    "            data_temp = data[int(ind)]\n",
    "            mini_y = data_temp[:, 0]\n",
    "            mini_X = data_temp[:, 1:]\n",
    "    \n",
    "            gradient = -2 * mini_X.T @ (mini_y - mini_X @ b)\n",
    "            b = b - step_size * gradient\n",
    "            \n",
    "            t += 1\n",
    "            \n",
    "            if t % n == 0:\n",
    "                gradient_norm = np.linalg.norm(gradient)\n",
    "                if gradient_norm < eps:\n",
    "                    break\n",
    "                    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5ff1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRSGD_alter (X, y, step_size = 0.001, n_iter = 1000, k = 100, eps = 1e-6):\n",
    "    '''\n",
    "    Stochastic Gradient Descent for OLS: \n",
    "        1. multiple observarions per iteration\n",
    "        2. sample with replacement\n",
    "    X is a n*p matrix\n",
    "    y is a n*1 vector\n",
    "    b is a p*1 vector\n",
    "    '''\n",
    "    \n",
    "    n, p = X.shape\n",
    "    \n",
    "    ones = np.ones((n, 1))\n",
    "    X = np.append(ones, X, axis = 1)\n",
    "        \n",
    "    b = np.zeros((p+1, 1))\n",
    "    \n",
    "    data = np.append(y, X, axis = 1)\n",
    "\n",
    "    t = 0\n",
    "    gradient_norm = 1\n",
    "    \n",
    "    while t < n_iter and gradient_norm >= eps:\n",
    "        \n",
    "        np.random.seed(t)\n",
    "        index = np.random.choice(n, k, replace=False)\n",
    "        data_temp = data[index]\n",
    "        mini_y = data_temp[:, 0]\n",
    "        mini_X = data_temp[:, 1:]\n",
    "    \n",
    "        gradient = -2/k * mini_X.T @ (mini_y - mini_X @ b)\n",
    "        b = b - step_size * gradient\n",
    "        \n",
    "        t += 1\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aca46edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for best step_size\n",
    "step_sizes = [0.01, 0.001, 0.0001, 0.00001]\n",
    "beta = []\n",
    "beta2 = []\n",
    "for i in range(len(step_sizes)):   \n",
    "    beta.append(LRSGD(X_train_scaled, y_train_scaled, step_size = step_sizes[i])) # models w/o interaction\n",
    "    beta2.append(LRSGD(X_train2_scaled, y_train_scaled, step_size = step_sizes[i])) # models w interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6eb696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform standardized coefficients to originals\n",
    "coef = []\n",
    "coef2 = []\n",
    "for i in range(len(step_sizes)):\n",
    "    coef.append(st2unst(beta[i], y_train, X_train))\n",
    "    coef2.append(st2unst(beta2[i], y_train, X_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ec040eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine best step_size by calculating average difference in coefficients between lr and sgd methods\n",
    "diff = []\n",
    "diff2 = []\n",
    "for i in range(len(step_sizes)):\n",
    "    dis = np.mean(np.abs(lr_beta - coef[i]))\n",
    "    dis2 = np.mean(np.abs(lr_beta2 - coef2[i]))\n",
    "    diff.append(dis)\n",
    "    diff2.append(dis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d0ddf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31522.254363902273, 11035.401876874985, 1366.1500260349385, 53686.811228807914]\n",
      "[65321.32148624168, 11785.1296189597, 47869.92478163912, 101032.85001803543]\n"
     ]
    }
   ],
   "source": [
    "print(diff)\n",
    "print(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c0c1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0.0001 as final step_size for model w/o interaction\n",
    "# use 0.001 as final step_size for model w interaction\n",
    "sgd_beta = coef[2]\n",
    "sgd_beta2 = coef2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e6cae2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.08329891e+04,  7.83401252e+04],\n",
       "        [-5.92969566e+04, -5.93424198e+04],\n",
       "        [ 3.68165620e+03,  7.97168242e+03],\n",
       "        [ 3.16685731e+02,  3.14402618e+02],\n",
       "        [-4.26736772e-01, -5.40341358e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare lr to gd results for models w/o interaction\n",
    "np.append(lr_beta, sgd_beta, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5639cca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.20752748e+05,  3.70765690e+05],\n",
       "        [-1.28706409e+05, -1.41001309e+05],\n",
       "        [-1.11008869e+05, -1.16985097e+05],\n",
       "        [ 3.08724841e+02,  3.02261869e+02],\n",
       "        [-4.24577540e-01, -4.73413535e-01],\n",
       "        [ 3.37536051e+04,  3.61738015e+04]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare lr to gd results for models w interaction\n",
    "np.append(lr_beta2, sgd_beta2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c69a3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5099282729266595\n",
      "0.5044362207387216\n"
     ]
    }
   ],
   "source": [
    "# perform part(a)\n",
    "\n",
    "# calculate R2 on training data\n",
    "sgd_y_pred_train = predict(X_train, sgd_beta)\n",
    "sgd_r2_train = r2_score(y_train, sgd_y_pred_train)\n",
    "print(sgd_r2_train)\n",
    "\n",
    "# calculate R2 on testing data\n",
    "sgd_y_pred_test = predict(X_test, sgd_beta)\n",
    "sgd_r2_test = r2_score(y_test, sgd_y_pred_test)\n",
    "print(sgd_r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d251038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15401446.89744386]]\n"
     ]
    }
   ],
   "source": [
    "# perform part(b)\n",
    "\n",
    "# predict price of Bill Gates' house\n",
    "sgd_y_pred_fancy = predict(np.matrix(X_fancy), sgd_beta)\n",
    "print(sgd_y_pred_fancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e81b1ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5165499943027383\n",
      "0.5097266407396426\n"
     ]
    }
   ],
   "source": [
    "# perform part(c)\n",
    "\n",
    "# calculate R2 on training data\n",
    "sgd_y_pred_train2 = predict(X_train2, sgd_beta2)\n",
    "sgd_r2_train2 = r2_score(y_train, sgd_y_pred_train2)\n",
    "print(sgd_r2_train2)\n",
    "\n",
    "# calculate R2 on testing data\n",
    "sgd_y_pred_test2 = predict(X_test2, sgd_beta2)\n",
    "sgd_r2_test2 = r2_score(y_test, sgd_y_pred_test2)\n",
    "print(sgd_r2_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3ed64",
   "metadata": {},
   "source": [
    "## 3\n",
    "see pdf file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
